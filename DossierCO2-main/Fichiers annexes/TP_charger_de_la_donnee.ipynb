{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0) chargement de spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/11/04 11:18:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#sans se connecter au cluster\n",
    "#spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "spark = SparkSession.\\\n",
    "        builder.\\\n",
    "        appName(\"pyspark-notebook\").\\\n",
    "        master(\"spark://spark-master:7077\").\\\n",
    "        config(\"spark.executor.memory\", \"2g\").\\\n",
    "        getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) lire de la donnée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1) lecture brute\n",
    "Chargez le fichier ville_1.csv dans une variable nommée df.\n",
    "\n",
    "Vous pouvez afficher votre donnée en utilisant la méthode take() ou la methode collect() de l'objet pyspark DataFrame (attention appeler collect() sur un dataframe est déconseillé si vous avez du vrai big data).\n",
    "\n",
    "L'objet possède aussi un attribut appelé dtypes, appelez cet attribut pour obtenir la liste des colonnes et leur type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('_c0', 'string')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path  = \"/opt/workspace/BigData/Datasets_Emission_CO2.csv\"\n",
    "# lecture d'un fichier de manière la plus brute\n",
    "df    = spark.read.load(path, format=\"csv\")\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-1.5.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas) (2022.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas) (2.8.2)\n",
      "Collecting numpy>=1.20.3\n",
      "  Downloading numpy-1.23.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Installing collected packages: numpy, pandas\n",
      "Successfully installed numpy-1.23.4 pandas-1.5.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Afrique du Sud</th>\n",
       "      <th>6,8</th>\n",
       "      <th>7,9</th>\n",
       "      <th>7,17</th>\n",
       "      <th>6,76</th>\n",
       "      <th>6,63</th>\n",
       "      <th>6,27</th>\n",
       "      <th>6,25</th>\n",
       "      <th>7,82</th>\n",
       "      <th>7,98</th>\n",
       "      <th>7,46</th>\n",
       "      <th>7,43</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Albanie</td>\n",
       "      <td>1,77</td>\n",
       "      <td>1,8</td>\n",
       "      <td>2,55</td>\n",
       "      <td>2,34</td>\n",
       "      <td>1,73</td>\n",
       "      <td>0,58</td>\n",
       "      <td>1</td>\n",
       "      <td>1,27</td>\n",
       "      <td>1,35</td>\n",
       "      <td>1,33</td>\n",
       "      <td>1,51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Algérie</td>\n",
       "      <td>0,58</td>\n",
       "      <td>0,81</td>\n",
       "      <td>1,43</td>\n",
       "      <td>1,86</td>\n",
       "      <td>1,98</td>\n",
       "      <td>1,92</td>\n",
       "      <td>1,97</td>\n",
       "      <td>2,33</td>\n",
       "      <td>2,65</td>\n",
       "      <td>3,27</td>\n",
       "      <td>3,16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Allemagne</td>\n",
       "      <td>12,49</td>\n",
       "      <td>12,37</td>\n",
       "      <td>13,39</td>\n",
       "      <td>12,93</td>\n",
       "      <td>11,84</td>\n",
       "      <td>10,54</td>\n",
       "      <td>9,97</td>\n",
       "      <td>9,67</td>\n",
       "      <td>9,45</td>\n",
       "      <td>8,93</td>\n",
       "      <td>8,7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Angola</td>\n",
       "      <td>0,23</td>\n",
       "      <td>0,26</td>\n",
       "      <td>0,3</td>\n",
       "      <td>0,27</td>\n",
       "      <td>0,32</td>\n",
       "      <td>0,27</td>\n",
       "      <td>0,28</td>\n",
       "      <td>0,31</td>\n",
       "      <td>0,65</td>\n",
       "      <td>0,71</td>\n",
       "      <td>0,61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arabie saoudite</td>\n",
       "      <td>2,08</td>\n",
       "      <td>3,03</td>\n",
       "      <td>10,21</td>\n",
       "      <td>8,93</td>\n",
       "      <td>9,26</td>\n",
       "      <td>10,23</td>\n",
       "      <td>11,3</td>\n",
       "      <td>12,47</td>\n",
       "      <td>15,28</td>\n",
       "      <td>16,84</td>\n",
       "      <td>16,16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Viêt Nam</td>\n",
       "      <td>0,37</td>\n",
       "      <td>0,35</td>\n",
       "      <td>0,28</td>\n",
       "      <td>0,3</td>\n",
       "      <td>0,26</td>\n",
       "      <td>0,38</td>\n",
       "      <td>0,57</td>\n",
       "      <td>0,96</td>\n",
       "      <td>1,45</td>\n",
       "      <td>1,84</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Yémen</td>\n",
       "      <td>0,19</td>\n",
       "      <td>0,26</td>\n",
       "      <td>0,43</td>\n",
       "      <td>0,49</td>\n",
       "      <td>0,52</td>\n",
       "      <td>0,62</td>\n",
       "      <td>0,75</td>\n",
       "      <td>0,92</td>\n",
       "      <td>0,95</td>\n",
       "      <td>0,42</td>\n",
       "      <td>0,32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>Yougoslavie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3,54</td>\n",
       "      <td>3,87</td>\n",
       "      <td>5,28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Zambie</td>\n",
       "      <td>0,78</td>\n",
       "      <td>0,87</td>\n",
       "      <td>0,56</td>\n",
       "      <td>0,39</td>\n",
       "      <td>0,32</td>\n",
       "      <td>0,22</td>\n",
       "      <td>0,16</td>\n",
       "      <td>0,18</td>\n",
       "      <td>0,12</td>\n",
       "      <td>0,21</td>\n",
       "      <td>0,35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>1,35</td>\n",
       "      <td>1,17</td>\n",
       "      <td>1,11</td>\n",
       "      <td>1,12</td>\n",
       "      <td>1,6</td>\n",
       "      <td>1,33</td>\n",
       "      <td>1,09</td>\n",
       "      <td>0,79</td>\n",
       "      <td>0,66</td>\n",
       "      <td>0,75</td>\n",
       "      <td>0,59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Afrique du Sud    6,8    7,9   7,17   6,76   6,63   6,27  6,25   7,82  \\\n",
       "0             Albanie   1,77    1,8   2,55   2,34   1,73   0,58     1   1,27   \n",
       "1             Algérie   0,58   0,81   1,43   1,86   1,98   1,92  1,97   2,33   \n",
       "2           Allemagne  12,49  12,37  13,39  12,93  11,84  10,54  9,97   9,67   \n",
       "3              Angola   0,23   0,26    0,3   0,27   0,32   0,27  0,28   0,31   \n",
       "4     Arabie saoudite   2,08   3,03  10,21   8,93   9,26  10,23  11,3  12,47   \n",
       "..                ...    ...    ...    ...    ...    ...    ...   ...    ...   \n",
       "140          Viêt Nam   0,37   0,35   0,28    0,3   0,26   0,38  0,57   0,96   \n",
       "141             Yémen   0,19   0,26   0,43   0,49   0,52   0,62  0,75   0,92   \n",
       "142       Yougoslavie    NaN   3,54   3,87   5,28    NaN    NaN   NaN    NaN   \n",
       "143            Zambie   0,78   0,87   0,56   0,39   0,32   0,22  0,16   0,18   \n",
       "144          Zimbabwe   1,35   1,17   1,11   1,12    1,6   1,33  1,09   0,79   \n",
       "\n",
       "      7,98   7,46   7,43  \n",
       "0     1,35   1,33   1,51  \n",
       "1     2,65   3,27   3,16  \n",
       "2     9,45   8,93    8,7  \n",
       "3     0,65   0,71   0,61  \n",
       "4    15,28  16,84  16,16  \n",
       "..     ...    ...    ...  \n",
       "140   1,45   1,84      2  \n",
       "141   0,95   0,42   0,32  \n",
       "142    NaN    NaN    NaN  \n",
       "143   0,12   0,21   0,35  \n",
       "144   0,66   0,75   0,59  \n",
       "\n",
       "[145 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(path,sep=\";\", header=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('_c0', 'string')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path  = \"/opt/workspace/BigData/PIB_Par_Tete_modifie.csv\"\n",
    "# lecture d'un fichier de manière la plus brute\n",
    "df    = spark.read.load(path, format=\"csv\")\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Australie</th>\n",
       "      <th>22327,5</th>\n",
       "      <th>23430,09</th>\n",
       "      <th>25594,62</th>\n",
       "      <th>27773,92</th>\n",
       "      <th>29856,67</th>\n",
       "      <th>33146,82</th>\n",
       "      <th>37933,18</th>\n",
       "      <th>42370,34</th>\n",
       "      <th>44478,98</th>\n",
       "      <th>47232,63</th>\n",
       "      <th>48116,44</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Autriche</td>\n",
       "      <td>21373,65</td>\n",
       "      <td>24405,49</td>\n",
       "      <td>28794,91</td>\n",
       "      <td>30910,61</td>\n",
       "      <td>35361,52</td>\n",
       "      <td>38125,62</td>\n",
       "      <td>43826,22</td>\n",
       "      <td>46591,87</td>\n",
       "      <td>48907,74</td>\n",
       "      <td>49942,06</td>\n",
       "      <td>51105,6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Belgique</td>\n",
       "      <td>20890,3</td>\n",
       "      <td>23692,89</td>\n",
       "      <td>27552,51</td>\n",
       "      <td>28810,99</td>\n",
       "      <td>33167,59</td>\n",
       "      <td>35296,31</td>\n",
       "      <td>40193,01</td>\n",
       "      <td>43290,08</td>\n",
       "      <td>44813,01</td>\n",
       "      <td>46201,68</td>\n",
       "      <td>47122,51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Canada</td>\n",
       "      <td>22226,76</td>\n",
       "      <td>24914,41</td>\n",
       "      <td>28295,53</td>\n",
       "      <td>30604,35</td>\n",
       "      <td>32488,54</td>\n",
       "      <td>33415,58</td>\n",
       "      <td>38857,67</td>\n",
       "      <td>41999,24</td>\n",
       "      <td>42169,96</td>\n",
       "      <td>44670,05</td>\n",
       "      <td>45417,37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chili</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>8729,19</td>\n",
       "      <td>12120,95</td>\n",
       "      <td>14255,69</td>\n",
       "      <td>16967,67</td>\n",
       "      <td>19617,71</td>\n",
       "      <td>22563,58</td>\n",
       "      <td>22705,13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Colombie</td>\n",
       "      <td>..</td>\n",
       "      <td>5693,4</td>\n",
       "      <td>6601,63</td>\n",
       "      <td>6841,05</td>\n",
       "      <td>7790,66</td>\n",
       "      <td>8948,42</td>\n",
       "      <td>8534,54</td>\n",
       "      <td>9579,23</td>\n",
       "      <td>11228,4</td>\n",
       "      <td>13330,56</td>\n",
       "      <td>13491,49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>R姿ublique tch述ue</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>22042,81</td>\n",
       "      <td>21323,53</td>\n",
       "      <td>23369,79</td>\n",
       "      <td>28414,53</td>\n",
       "      <td>31254,65</td>\n",
       "      <td>33909,31</td>\n",
       "      <td>36405,97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Danemark</td>\n",
       "      <td>25368,42</td>\n",
       "      <td>26228,42</td>\n",
       "      <td>29532,78</td>\n",
       "      <td>33880,94</td>\n",
       "      <td>36195,77</td>\n",
       "      <td>39912,53</td>\n",
       "      <td>45363,34</td>\n",
       "      <td>47742,29</td>\n",
       "      <td>47134,28</td>\n",
       "      <td>49058,14</td>\n",
       "      <td>51329,97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Estonie</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>11871,9</td>\n",
       "      <td>16368,39</td>\n",
       "      <td>23636,98</td>\n",
       "      <td>23372,59</td>\n",
       "      <td>27387,59</td>\n",
       "      <td>29888,18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Finlande</td>\n",
       "      <td>17386,25</td>\n",
       "      <td>20616,94</td>\n",
       "      <td>23751,78</td>\n",
       "      <td>26666,75</td>\n",
       "      <td>31057,84</td>\n",
       "      <td>29700,25</td>\n",
       "      <td>37615,22</td>\n",
       "      <td>42228,33</td>\n",
       "      <td>43253,59</td>\n",
       "      <td>42490,21</td>\n",
       "      <td>44852,7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>France</td>\n",
       "      <td>20383,13</td>\n",
       "      <td>22753,96</td>\n",
       "      <td>26273,06</td>\n",
       "      <td>27672,48</td>\n",
       "      <td>31778,68</td>\n",
       "      <td>33158,78</td>\n",
       "      <td>37450,37</td>\n",
       "      <td>39253,22</td>\n",
       "      <td>39730,93</td>\n",
       "      <td>40829,89</td>\n",
       "      <td>41886,43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Allemagne</td>\n",
       "      <td>21328,28</td>\n",
       "      <td>23212,92</td>\n",
       "      <td>27523,14</td>\n",
       "      <td>29693,99</td>\n",
       "      <td>34182,92</td>\n",
       "      <td>36801,54</td>\n",
       "      <td>40319,79</td>\n",
       "      <td>41469,45</td>\n",
       "      <td>44551,69</td>\n",
       "      <td>47609,56</td>\n",
       "      <td>49389,27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Gr縦e</td>\n",
       "      <td>16869,29</td>\n",
       "      <td>19515,28</td>\n",
       "      <td>22455,9</td>\n",
       "      <td>21946,6</td>\n",
       "      <td>22819,53</td>\n",
       "      <td>23598,02</td>\n",
       "      <td>27587,57</td>\n",
       "      <td>32829,96</td>\n",
       "      <td>31904,69</td>\n",
       "      <td>26760,15</td>\n",
       "      <td>27086,48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Hongrie</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>16174,89</td>\n",
       "      <td>18897,79</td>\n",
       "      <td>23767,64</td>\n",
       "      <td>23828,96</td>\n",
       "      <td>26798,85</td>\n",
       "      <td>28719,39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Islande</td>\n",
       "      <td>18986,67</td>\n",
       "      <td>21652,95</td>\n",
       "      <td>28048,49</td>\n",
       "      <td>29716,85</td>\n",
       "      <td>32913,42</td>\n",
       "      <td>31774,83</td>\n",
       "      <td>39188,09</td>\n",
       "      <td>45518,55</td>\n",
       "      <td>44785,87</td>\n",
       "      <td>49203,29</td>\n",
       "      <td>52499,4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Irlande</td>\n",
       "      <td>13897,5</td>\n",
       "      <td>16003,08</td>\n",
       "      <td>18679,28</td>\n",
       "      <td>20346,93</td>\n",
       "      <td>25862,38</td>\n",
       "      <td>31578,7</td>\n",
       "      <td>46872,64</td>\n",
       "      <td>55603,29</td>\n",
       "      <td>51697,35</td>\n",
       "      <td>69165,9</td>\n",
       "      <td>75201,83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Isra鼠</td>\n",
       "      <td>15202,88</td>\n",
       "      <td>17681,42</td>\n",
       "      <td>18333,07</td>\n",
       "      <td>19656,07</td>\n",
       "      <td>22143,55</td>\n",
       "      <td>25623,17</td>\n",
       "      <td>28975,91</td>\n",
       "      <td>29094,39</td>\n",
       "      <td>32747,99</td>\n",
       "      <td>35877,15</td>\n",
       "      <td>37609,64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Italie</td>\n",
       "      <td>19458,17</td>\n",
       "      <td>21775,49</td>\n",
       "      <td>26592,87</td>\n",
       "      <td>28827,5</td>\n",
       "      <td>33541,95</td>\n",
       "      <td>35706,98</td>\n",
       "      <td>39472,06</td>\n",
       "      <td>40440,96</td>\n",
       "      <td>38760,49</td>\n",
       "      <td>37206,33</td>\n",
       "      <td>38461,31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Japon</td>\n",
       "      <td>17027,35</td>\n",
       "      <td>19074,62</td>\n",
       "      <td>22569,49</td>\n",
       "      <td>26741,54</td>\n",
       "      <td>33214,03</td>\n",
       "      <td>35305,95</td>\n",
       "      <td>36772,69</td>\n",
       "      <td>38725,89</td>\n",
       "      <td>38545,65</td>\n",
       "      <td>40908,78</td>\n",
       "      <td>42041,31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Cor仔</td>\n",
       "      <td>2826,8</td>\n",
       "      <td>3832,95</td>\n",
       "      <td>5350,2</td>\n",
       "      <td>7850</td>\n",
       "      <td>12354,53</td>\n",
       "      <td>17688,19</td>\n",
       "      <td>22415,84</td>\n",
       "      <td>27957,17</td>\n",
       "      <td>33574,01</td>\n",
       "      <td>37902,36</td>\n",
       "      <td>39980,22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Lituanie</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>9978,12</td>\n",
       "      <td>12985,01</td>\n",
       "      <td>19743,02</td>\n",
       "      <td>22452,58</td>\n",
       "      <td>28834,46</td>\n",
       "      <td>31660,56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Lettonie</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>9003,89</td>\n",
       "      <td>12184,06</td>\n",
       "      <td>19070,67</td>\n",
       "      <td>19862,13</td>\n",
       "      <td>24975,48</td>\n",
       "      <td>26905,75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Luxembourg</td>\n",
       "      <td>36937,22</td>\n",
       "      <td>39603,39</td>\n",
       "      <td>43644,99</td>\n",
       "      <td>49048,62</td>\n",
       "      <td>67517,36</td>\n",
       "      <td>76432,92</td>\n",
       "      <td>94485,12</td>\n",
       "      <td>103402,81</td>\n",
       "      <td>108840,71</td>\n",
       "      <td>107898,3</td>\n",
       "      <td>109460,5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Mexique</td>\n",
       "      <td>10080,42</td>\n",
       "      <td>11680,25</td>\n",
       "      <td>13921,31</td>\n",
       "      <td>13695,49</td>\n",
       "      <td>13463,83</td>\n",
       "      <td>13644,54</td>\n",
       "      <td>16531,41</td>\n",
       "      <td>16738,42</td>\n",
       "      <td>16893,58</td>\n",
       "      <td>18454,8</td>\n",
       "      <td>18945,73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Pays-Bas</td>\n",
       "      <td>24146,26</td>\n",
       "      <td>26398,72</td>\n",
       "      <td>29343,19</td>\n",
       "      <td>30297,99</td>\n",
       "      <td>34624,97</td>\n",
       "      <td>37495,78</td>\n",
       "      <td>45016,75</td>\n",
       "      <td>46959,29</td>\n",
       "      <td>49396,33</td>\n",
       "      <td>50288,35</td>\n",
       "      <td>52296,81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Nouvelle-Z四ande</td>\n",
       "      <td>20875,97</td>\n",
       "      <td>22860,04</td>\n",
       "      <td>22596,58</td>\n",
       "      <td>25274,78</td>\n",
       "      <td>24850,68</td>\n",
       "      <td>26471,45</td>\n",
       "      <td>29323,71</td>\n",
       "      <td>33247,52</td>\n",
       "      <td>34072,89</td>\n",
       "      <td>37246,95</td>\n",
       "      <td>38649,87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Norv夙e</td>\n",
       "      <td>22688,58</td>\n",
       "      <td>26539,76</td>\n",
       "      <td>32521,49</td>\n",
       "      <td>37925,08</td>\n",
       "      <td>40389,35</td>\n",
       "      <td>47215,02</td>\n",
       "      <td>54752,01</td>\n",
       "      <td>59301,94</td>\n",
       "      <td>58805,84</td>\n",
       "      <td>60352,72</td>\n",
       "      <td>61387,58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Pologne</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>10953,75</td>\n",
       "      <td>12120,34</td>\n",
       "      <td>15684,84</td>\n",
       "      <td>18271,13</td>\n",
       "      <td>22686,49</td>\n",
       "      <td>26495,81</td>\n",
       "      <td>28705,12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Portugal</td>\n",
       "      <td>12515</td>\n",
       "      <td>13823,43</td>\n",
       "      <td>16505,74</td>\n",
       "      <td>16830,44</td>\n",
       "      <td>22426,82</td>\n",
       "      <td>24327,89</td>\n",
       "      <td>28959,72</td>\n",
       "      <td>29620,83</td>\n",
       "      <td>30308,45</td>\n",
       "      <td>29660,84</td>\n",
       "      <td>31496,61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>R姿ublique slovaque</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>13825,61</td>\n",
       "      <td>16309,42</td>\n",
       "      <td>20894,79</td>\n",
       "      <td>26551,67</td>\n",
       "      <td>30062,18</td>\n",
       "      <td>31453,91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Slov始ie</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>20598,67</td>\n",
       "      <td>20112,29</td>\n",
       "      <td>24582,98</td>\n",
       "      <td>29124,03</td>\n",
       "      <td>31204,38</td>\n",
       "      <td>31631,84</td>\n",
       "      <td>34171,54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Espagne</td>\n",
       "      <td>15848,29</td>\n",
       "      <td>18886,73</td>\n",
       "      <td>19709,25</td>\n",
       "      <td>20622,11</td>\n",
       "      <td>25410,36</td>\n",
       "      <td>27123,58</td>\n",
       "      <td>32467,84</td>\n",
       "      <td>35442,94</td>\n",
       "      <td>34860,13</td>\n",
       "      <td>34929,21</td>\n",
       "      <td>36960,44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Su重e</td>\n",
       "      <td>23292,6</td>\n",
       "      <td>25915,1</td>\n",
       "      <td>27299,28</td>\n",
       "      <td>29983,06</td>\n",
       "      <td>32932,02</td>\n",
       "      <td>33006,55</td>\n",
       "      <td>39168,96</td>\n",
       "      <td>43811,1</td>\n",
       "      <td>46078,02</td>\n",
       "      <td>49103,13</td>\n",
       "      <td>50085,59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Suisse</td>\n",
       "      <td>42720,11</td>\n",
       "      <td>42334,02</td>\n",
       "      <td>46156,82</td>\n",
       "      <td>48613,98</td>\n",
       "      <td>54018,75</td>\n",
       "      <td>52047,04</td>\n",
       "      <td>57095,13</td>\n",
       "      <td>59393,24</td>\n",
       "      <td>63773,73</td>\n",
       "      <td>66020,21</td>\n",
       "      <td>67066,08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>T殲kiye</td>\n",
       "      <td>7934,78</td>\n",
       "      <td>9001,03</td>\n",
       "      <td>9124,56</td>\n",
       "      <td>10220,1</td>\n",
       "      <td>12223,9</td>\n",
       "      <td>13206,01</td>\n",
       "      <td>15066,45</td>\n",
       "      <td>17966,7</td>\n",
       "      <td>19647,9</td>\n",
       "      <td>25855,91</td>\n",
       "      <td>27970,14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Royaume-Uni</td>\n",
       "      <td>19137,3</td>\n",
       "      <td>20324,53</td>\n",
       "      <td>22655,73</td>\n",
       "      <td>25348,36</td>\n",
       "      <td>29747,19</td>\n",
       "      <td>31795,44</td>\n",
       "      <td>37080,56</td>\n",
       "      <td>40762,02</td>\n",
       "      <td>40160,36</td>\n",
       "      <td>42916,97</td>\n",
       "      <td>44193,91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>フats-Unis</td>\n",
       "      <td>25796,15</td>\n",
       "      <td>27379,33</td>\n",
       "      <td>31093,38</td>\n",
       "      <td>34923,1</td>\n",
       "      <td>39215,83</td>\n",
       "      <td>41772,05</td>\n",
       "      <td>48705,38</td>\n",
       "      <td>52704,77</td>\n",
       "      <td>52887,07</td>\n",
       "      <td>56731,07</td>\n",
       "      <td>58190,22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Australie   22327,5  23430,09  25594,62  27773,92  29856,67  \\\n",
       "0             Autriche  21373,65  24405,49  28794,91  30910,61  35361,52   \n",
       "1             Belgique   20890,3  23692,89  27552,51  28810,99  33167,59   \n",
       "2               Canada  22226,76  24914,41  28295,53  30604,35  32488,54   \n",
       "3                Chili        ..        ..        ..        ..   8729,19   \n",
       "4             Colombie        ..    5693,4   6601,63   6841,05   7790,66   \n",
       "5     R姿ublique tch述ue        ..        ..        ..        ..  22042,81   \n",
       "6             Danemark  25368,42  26228,42  29532,78  33880,94  36195,77   \n",
       "7              Estonie        ..        ..        ..        ..        ..   \n",
       "8             Finlande  17386,25  20616,94  23751,78  26666,75  31057,84   \n",
       "9               France  20383,13  22753,96  26273,06  27672,48  31778,68   \n",
       "10           Allemagne  21328,28  23212,92  27523,14  29693,99  34182,92   \n",
       "11                Gr縦e  16869,29  19515,28   22455,9   21946,6  22819,53   \n",
       "12             Hongrie        ..        ..        ..        ..        ..   \n",
       "13             Islande  18986,67  21652,95  28048,49  29716,85  32913,42   \n",
       "14             Irlande   13897,5  16003,08  18679,28  20346,93  25862,38   \n",
       "15               Isra鼠  15202,88  17681,42  18333,07  19656,07  22143,55   \n",
       "16              Italie  19458,17  21775,49  26592,87   28827,5  33541,95   \n",
       "17               Japon  17027,35  19074,62  22569,49  26741,54  33214,03   \n",
       "18                Cor仔    2826,8   3832,95    5350,2      7850  12354,53   \n",
       "19            Lituanie        ..        ..        ..        ..        ..   \n",
       "20            Lettonie        ..        ..        ..        ..        ..   \n",
       "21          Luxembourg  36937,22  39603,39  43644,99  49048,62  67517,36   \n",
       "22             Mexique  10080,42  11680,25  13921,31  13695,49  13463,83   \n",
       "23            Pays-Bas  24146,26  26398,72  29343,19  30297,99  34624,97   \n",
       "24     Nouvelle-Z四ande  20875,97  22860,04  22596,58  25274,78  24850,68   \n",
       "25              Norv夙e  22688,58  26539,76  32521,49  37925,08  40389,35   \n",
       "26             Pologne        ..        ..        ..        ..  10953,75   \n",
       "27            Portugal     12515  13823,43  16505,74  16830,44  22426,82   \n",
       "28  R姿ublique slovaque        ..        ..        ..        ..        ..   \n",
       "29             Slov始ie        ..        ..        ..        ..  20598,67   \n",
       "30             Espagne  15848,29  18886,73  19709,25  20622,11  25410,36   \n",
       "31                Su重e   23292,6   25915,1  27299,28  29983,06  32932,02   \n",
       "32              Suisse  42720,11  42334,02  46156,82  48613,98  54018,75   \n",
       "33              T殲kiye   7934,78   9001,03   9124,56   10220,1   12223,9   \n",
       "34         Royaume-Uni   19137,3  20324,53  22655,73  25348,36  29747,19   \n",
       "35           フats-Unis  25796,15  27379,33  31093,38   34923,1  39215,83   \n",
       "\n",
       "    33146,82  37933,18   42370,34   44478,98  47232,63  48116,44  \n",
       "0   38125,62  43826,22   46591,87   48907,74  49942,06   51105,6  \n",
       "1   35296,31  40193,01   43290,08   44813,01  46201,68  47122,51  \n",
       "2   33415,58  38857,67   41999,24   42169,96  44670,05  45417,37  \n",
       "3   12120,95  14255,69   16967,67   19617,71  22563,58  22705,13  \n",
       "4    8948,42   8534,54    9579,23    11228,4  13330,56  13491,49  \n",
       "5   21323,53  23369,79   28414,53   31254,65  33909,31  36405,97  \n",
       "6   39912,53  45363,34   47742,29   47134,28  49058,14  51329,97  \n",
       "7    11871,9  16368,39   23636,98   23372,59  27387,59  29888,18  \n",
       "8   29700,25  37615,22   42228,33   43253,59  42490,21   44852,7  \n",
       "9   33158,78  37450,37   39253,22   39730,93  40829,89  41886,43  \n",
       "10  36801,54  40319,79   41469,45   44551,69  47609,56  49389,27  \n",
       "11  23598,02  27587,57   32829,96   31904,69  26760,15  27086,48  \n",
       "12  16174,89  18897,79   23767,64   23828,96  26798,85  28719,39  \n",
       "13  31774,83  39188,09   45518,55   44785,87  49203,29   52499,4  \n",
       "14   31578,7  46872,64   55603,29   51697,35   69165,9  75201,83  \n",
       "15  25623,17  28975,91   29094,39   32747,99  35877,15  37609,64  \n",
       "16  35706,98  39472,06   40440,96   38760,49  37206,33  38461,31  \n",
       "17  35305,95  36772,69   38725,89   38545,65  40908,78  42041,31  \n",
       "18  17688,19  22415,84   27957,17   33574,01  37902,36  39980,22  \n",
       "19   9978,12  12985,01   19743,02   22452,58  28834,46  31660,56  \n",
       "20   9003,89  12184,06   19070,67   19862,13  24975,48  26905,75  \n",
       "21  76432,92  94485,12  103402,81  108840,71  107898,3  109460,5  \n",
       "22  13644,54  16531,41   16738,42   16893,58   18454,8  18945,73  \n",
       "23  37495,78  45016,75   46959,29   49396,33  50288,35  52296,81  \n",
       "24  26471,45  29323,71   33247,52   34072,89  37246,95  38649,87  \n",
       "25  47215,02  54752,01   59301,94   58805,84  60352,72  61387,58  \n",
       "26  12120,34  15684,84   18271,13   22686,49  26495,81  28705,12  \n",
       "27  24327,89  28959,72   29620,83   30308,45  29660,84  31496,61  \n",
       "28  13825,61  16309,42   20894,79   26551,67  30062,18  31453,91  \n",
       "29  20112,29  24582,98   29124,03   31204,38  31631,84  34171,54  \n",
       "30  27123,58  32467,84   35442,94   34860,13  34929,21  36960,44  \n",
       "31  33006,55  39168,96    43811,1   46078,02  49103,13  50085,59  \n",
       "32  52047,04  57095,13   59393,24   63773,73  66020,21  67066,08  \n",
       "33  13206,01  15066,45    17966,7    19647,9  25855,91  27970,14  \n",
       "34  31795,44  37080,56   40762,02   40160,36  42916,97  44193,91  \n",
       "35  41772,05  48705,38   52704,77   52887,07  56731,07  58190,22  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(path,sep=\";\", header=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+\n",
      "|                 _c0| 1971| 1975| 1980| 1985| 1990| 1995| 2000| 2005| 2010| 2015| 2017|\n",
      "+--------------------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+\n",
      "|      Afrique du Sud|  6,8|  7,9| 7,17| 6,76| 6,63| 6,27| 6,25| 7,82| 7,98| 7,46| 7,43|\n",
      "|             Albanie| 1,77|  1,8| 2,55| 2,34| 1,73| 0,58|    1| 1,27| 1,35| 1,33| 1,51|\n",
      "|             Algérie| 0,58| 0,81| 1,43| 1,86| 1,98| 1,92| 1,97| 2,33| 2,65| 3,27| 3,16|\n",
      "|           Allemagne|12,49|12,37|13,39|12,93|11,84|10,54| 9,97| 9,67| 9,45| 8,93|  8,7|\n",
      "|              Angola| 0,23| 0,26|  0,3| 0,27| 0,32| 0,27| 0,28| 0,31| 0,65| 0,71| 0,61|\n",
      "|     Arabie saoudite| 2,08| 3,03|10,21| 8,93| 9,26|10,23| 11,3|12,47|15,28|16,84|16,16|\n",
      "|           Argentine| 3,39| 3,27| 3,39| 2,89| 3,04| 3,35| 3,76| 3,82| 4,22| 4,39| 4,14|\n",
      "|             Arménie| null| null| null| null| 5,61| 1,05| 1,12| 1,39| 1,41| 1,61| 1,76|\n",
      "|           Australie|10,86|12,85|13,96|13,84|15,03|15,66|17,36|18,18|17,42|15,72|15,63|\n",
      "|            Autriche| 6,48| 6,53|  7,2| 6,96| 7,33| 7,49| 7,72| 9,04| 8,17| 7,24| 7,38|\n",
      "|         Azerbaïdjan| null| null| null| null| 7,47| 4,21| 3,39| 3,46|  2,6| 3,19| 3,12|\n",
      "|             Bahreïn|13,15|19,59|20,11|21,72|21,53|23,86|23,82|23,13|20,59|21,92|19,97|\n",
      "|          Bangladesh| 0,04| 0,06| 0,08| 0,08| 0,11| 0,14| 0,16| 0,22| 0,33| 0,44| 0,48|\n",
      "|            Belgique|12,21|11,81|12,74|10,25|10,66|10,99| 11,1|10,25| 9,51| 8,24| 7,96|\n",
      "|               Bénin|  0,1| 0,14| 0,11| 0,11| 0,05| 0,04| 0,21| 0,34|  0,5|  0,5| 0,61|\n",
      "|         Biélorussie| null| null| null| null|  9,8| 5,59| 5,22| 5,69| 6,27| 5,55| 5,69|\n",
      "|            Birmanie| 0,17| 0,13| 0,15| 0,15|  0,1| 0,16|  0,2| 0,22| 0,16| 0,36| 0,57|\n",
      "|             Bolivie| 0,47| 0,64| 0,75| 0,69| 0,75| 0,91| 0,85| 0,99| 1,38|  1,7| 1,98|\n",
      "|  Bosnie-Herzégovine| null| null| null| null| 5,37| 0,85| 3,64| 4,19|  5,5| 5,44| 6,37|\n",
      "|            Botswana| null| null| null| 1,26| 2,04| 2,03| 2,33| 2,31| 1,62|  3,2| 3,37|\n",
      "|              Brésil|  0,9|  1,2| 1,39| 1,15| 1,23|  1,4| 1,67| 1,66| 1,88| 2,19| 2,04|\n",
      "|              Brunei| 2,93| 8,69| 13,6|13,09|12,59|15,16|13,29|13,21|17,64| 14,3|15,64|\n",
      "|            Bulgarie| 7,48| 8,41|  9,6| 9,17| 8,55| 6,27| 5,16| 6,07|    6| 6,09| 6,05|\n",
      "|            Cambodge| null| null| null| null| null| 0,14| 0,16|  0,2| 0,32| 0,52| 0,67|\n",
      "|            Cameroun| 0,11| 0,14| 0,19| 0,24| 0,23| 0,18| 0,18| 0,17| 0,25| 0,26| 0,26|\n",
      "|              Canada|15,49| 16,3|17,22|15,24|15,15|15,32|16,82|16,75|15,57|15,12|14,99|\n",
      "|               Chili| 2,16| 1,64| 1,92| 1,62| 2,23| 2,58| 3,16| 3,34| 4,01|  4,5| 4,65|\n",
      "|               Chine| 0,93| 1,12| 1,39| 1,55| 1,84| 2,41| 2,46| 4,15| 5,83| 6,64| 6,68|\n",
      "|              Chypre| 2,83| 3,28| 5,09| 5,14| 6,79| 7,83| 9,14| 9,62| 8,87| 6,97| 7,45|\n",
      "|            Colombie| 1,18| 1,14| 1,26| 1,27| 1,34| 1,45| 1,34| 1,24| 1,31| 1,62| 1,53|\n",
      "|       Corée du Nord| 4,67| 4,83| 6,19| 6,86| 5,76|  3,5| 3,05| 3,15|    2| 0,89| 0,77|\n",
      "|        Corée du Sud| 1,61|  2,2|  3,3| 3,82| 5,41| 7,92| 9,19|  9,5|11,12|11,41|11,66|\n",
      "|          Costa Rica| 0,67| 0,83|  0,9| 0,71| 0,84| 1,27| 1,15| 1,28| 1,46| 1,44| 1,55|\n",
      "|       Côte d'Ivoire| 0,44| 0,46| 0,41|  0,3| 0,22| 0,22| 0,38| 0,32| 0,31| 0,42| 0,42|\n",
      "|             Croatie| null| null| null| null| 4,25| 3,17| 3,79| 4,48| 4,13| 3,69| 3,92|\n",
      "|                Cuba| 2,35| 2,56|  3,1| 3,19| 3,22| 2,06| 2,45| 2,22|  2,6| 2,34| 2,28|\n",
      "|             Curaçao|90,15|60,33|50,15|24,58| 14,1|13,23|26,77|27,16|19,11|29,59|23,28|\n",
      "|            Danemark|11,17| 10,4|12,31|11,94| 9,92|11,16| 9,52| 8,95| 8,52| 5,62| 5,42|\n",
      "|              Égypte| 0,56| 0,65| 0,92| 1,28| 1,36| 1,28| 1,43| 1,88|  2,1| 2,13| 2,14|\n",
      "| Émirats arabes unis| 8,83| 8,88|18,45|25,62| 27,9|28,44|25,31|24,27|18,69|20,38|20,91|\n",
      "|            Équateur| 0,56| 0,85| 1,31| 1,29|  1,3| 1,46| 1,44| 1,74| 2,15| 2,28| 2,06|\n",
      "|            Érythrée| null| null| null| null| null| 0,25| 0,18| 0,15| 0,11| 0,12| 0,12|\n",
      "|             Espagne| 3,44| 4,33|  4,9| 4,45| 5,15| 5,75| 6,87| 7,64| 5,63| 5,32| 5,45|\n",
      "|             Estonie| null| null| null| null|22,06|10,97|10,31|12,32|13,93|11,51|12,14|\n",
      "|          États-Unis|20,65|20,17|20,18|18,93| 19,2|19,03|20,29|19,27|17,28|15,32|14,61|\n",
      "|            Éthiopie| 0,05| 0,04| 0,04| 0,03| 0,05| 0,04| 0,05| 0,06| 0,07|  0,1| 0,12|\n",
      "|            Finlande| 8,64| 9,38|11,48| 9,85| 10,8|10,91|10,55|10,47|11,56| 7,74| 7,73|\n",
      "|              France| 8,07| 7,85| 8,25| 6,21| 5,94| 5,78| 5,99| 5,89| 5,25| 4,39| 4,56|\n",
      "|               Gabon| 0,79| 1,17| 1,77| 2,03| 0,96| 1,21| 1,19| 1,24| 1,62| 1,68| 1,66|\n",
      "|             Géorgie| null| null| null| null| 6,97| 1,72| 1,05| 0,97| 1,27| 2,26| 2,35|\n",
      "+--------------------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType \n",
    "from pyspark.sql.types import ArrayType, DoubleType, BooleanType\n",
    "from pyspark.sql.functions import col,array_contains\n",
    "\n",
    "spark = SparkSession.\\\n",
    "        builder.\\\n",
    "        appName(\"pyspark-notebook\").\\\n",
    "        master(\"spark://spark-master:7077\").\\\n",
    "        config(\"spark.executor.memory\", \"2g\").\\\n",
    "        getOrCreate()\n",
    "\n",
    "df3 = spark.read.options(header='True', delimiter=';') \\\n",
    "  .csv(\"/opt/workspace/BigData/Datasets_Emission_CO2.csv\")\n",
    "\n",
    "#df3.printSchema()df = spark.read.csv(\"/opt/workspace/ProjetBigData/PIB_Par_Tete_modifie.csv\")\n",
    "\n",
    "df3.show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+--------+--------+--------+--------+--------+--------+---------+---------+--------+--------+\n",
      "|                _c0|    1971|    1975|    1980|    1985|    1990|    1995|    2000|     2005|     2010|    2015|    2017|\n",
      "+-------------------+--------+--------+--------+--------+--------+--------+--------+---------+---------+--------+--------+\n",
      "|          Australie| 22327,5|23430,09|25594,62|27773,92|29856,67|33146,82|37933,18| 42370,34| 44478,98|47232,63|48116,44|\n",
      "|           Autriche|21373,65|24405,49|28794,91|30910,61|35361,52|38125,62|43826,22| 46591,87| 48907,74|49942,06| 51105,6|\n",
      "|           Belgique| 20890,3|23692,89|27552,51|28810,99|33167,59|35296,31|40193,01| 43290,08| 44813,01|46201,68|47122,51|\n",
      "|             Canada|22226,76|24914,41|28295,53|30604,35|32488,54|33415,58|38857,67| 41999,24| 42169,96|44670,05|45417,37|\n",
      "|              Chili|      ..|      ..|      ..|      ..| 8729,19|12120,95|14255,69| 16967,67| 19617,71|22563,58|22705,13|\n",
      "|           Colombie|      ..|  5693,4| 6601,63| 6841,05| 7790,66| 8948,42| 8534,54|  9579,23|  11228,4|13330,56|13491,49|\n",
      "| R姿ublique tch述ue|      ..|      ..|      ..|      ..|22042,81|21323,53|23369,79| 28414,53| 31254,65|33909,31|36405,97|\n",
      "|           Danemark|25368,42|26228,42|29532,78|33880,94|36195,77|39912,53|45363,34| 47742,29| 47134,28|49058,14|51329,97|\n",
      "|            Estonie|      ..|      ..|      ..|      ..|      ..| 11871,9|16368,39| 23636,98| 23372,59|27387,59|29888,18|\n",
      "|           Finlande|17386,25|20616,94|23751,78|26666,75|31057,84|29700,25|37615,22| 42228,33| 43253,59|42490,21| 44852,7|\n",
      "|             France|20383,13|22753,96|26273,06|27672,48|31778,68|33158,78|37450,37| 39253,22| 39730,93|40829,89|41886,43|\n",
      "|          Allemagne|21328,28|23212,92|27523,14|29693,99|34182,92|36801,54|40319,79| 41469,45| 44551,69|47609,56|49389,27|\n",
      "|              Gr縦e|16869,29|19515,28| 22455,9| 21946,6|22819,53|23598,02|27587,57| 32829,96| 31904,69|26760,15|27086,48|\n",
      "|            Hongrie|      ..|      ..|      ..|      ..|      ..|16174,89|18897,79| 23767,64| 23828,96|26798,85|28719,39|\n",
      "|            Islande|18986,67|21652,95|28048,49|29716,85|32913,42|31774,83|39188,09| 45518,55| 44785,87|49203,29| 52499,4|\n",
      "|            Irlande| 13897,5|16003,08|18679,28|20346,93|25862,38| 31578,7|46872,64| 55603,29| 51697,35| 69165,9|75201,83|\n",
      "|             Isra鼠|15202,88|17681,42|18333,07|19656,07|22143,55|25623,17|28975,91| 29094,39| 32747,99|35877,15|37609,64|\n",
      "|             Italie|19458,17|21775,49|26592,87| 28827,5|33541,95|35706,98|39472,06| 40440,96| 38760,49|37206,33|38461,31|\n",
      "|              Japon|17027,35|19074,62|22569,49|26741,54|33214,03|35305,95|36772,69| 38725,89| 38545,65|40908,78|42041,31|\n",
      "|              Cor仔|  2826,8| 3832,95|  5350,2|    7850|12354,53|17688,19|22415,84| 27957,17| 33574,01|37902,36|39980,22|\n",
      "|           Lituanie|      ..|      ..|      ..|      ..|      ..| 9978,12|12985,01| 19743,02| 22452,58|28834,46|31660,56|\n",
      "|           Lettonie|      ..|      ..|      ..|      ..|      ..| 9003,89|12184,06| 19070,67| 19862,13|24975,48|26905,75|\n",
      "|         Luxembourg|36937,22|39603,39|43644,99|49048,62|67517,36|76432,92|94485,12|103402,81|108840,71|107898,3|109460,5|\n",
      "|            Mexique|10080,42|11680,25|13921,31|13695,49|13463,83|13644,54|16531,41| 16738,42| 16893,58| 18454,8|18945,73|\n",
      "|           Pays-Bas|24146,26|26398,72|29343,19|30297,99|34624,97|37495,78|45016,75| 46959,29| 49396,33|50288,35|52296,81|\n",
      "|   Nouvelle-Z四ande|20875,97|22860,04|22596,58|25274,78|24850,68|26471,45|29323,71| 33247,52| 34072,89|37246,95|38649,87|\n",
      "|            Norv夙e|22688,58|26539,76|32521,49|37925,08|40389,35|47215,02|54752,01| 59301,94| 58805,84|60352,72|61387,58|\n",
      "|            Pologne|      ..|      ..|      ..|      ..|10953,75|12120,34|15684,84| 18271,13| 22686,49|26495,81|28705,12|\n",
      "|           Portugal|   12515|13823,43|16505,74|16830,44|22426,82|24327,89|28959,72| 29620,83| 30308,45|29660,84|31496,61|\n",
      "|R姿ublique slovaque|      ..|      ..|      ..|      ..|      ..|13825,61|16309,42| 20894,79| 26551,67|30062,18|31453,91|\n",
      "|           Slov始ie|      ..|      ..|      ..|      ..|20598,67|20112,29|24582,98| 29124,03| 31204,38|31631,84|34171,54|\n",
      "|            Espagne|15848,29|18886,73|19709,25|20622,11|25410,36|27123,58|32467,84| 35442,94| 34860,13|34929,21|36960,44|\n",
      "|              Su重e| 23292,6| 25915,1|27299,28|29983,06|32932,02|33006,55|39168,96|  43811,1| 46078,02|49103,13|50085,59|\n",
      "|             Suisse|42720,11|42334,02|46156,82|48613,98|54018,75|52047,04|57095,13| 59393,24| 63773,73|66020,21|67066,08|\n",
      "|            T殲kiye| 7934,78| 9001,03| 9124,56| 10220,1| 12223,9|13206,01|15066,45|  17966,7|  19647,9|25855,91|27970,14|\n",
      "|        Royaume-Uni| 19137,3|20324,53|22655,73|25348,36|29747,19|31795,44|37080,56| 40762,02| 40160,36|42916,97|44193,91|\n",
      "|         フats-Unis|25796,15|27379,33|31093,38| 34923,1|39215,83|41772,05|48705,38| 52704,77| 52887,07|56731,07|58190,22|\n",
      "+-------------------+--------+--------+--------+--------+--------+--------+--------+---------+---------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4 = spark.read.options(header='True', delimiter=';') \\\n",
    "  .csv(\"/opt/workspace/BigData/PIB_Par_Tete_modifie.csv\")\n",
    "\n",
    "#df3.printSchema()df = spark.read.csv(\"/opt/workspace/ProjetBigData/PIB_Par_Tete_modifie.csv\")\n",
    "\n",
    "df4.show(40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                 _c0|\n",
      "+--------------------+\n",
      "|;1971;1975;1980;1...|\n",
      "|    Afrique du Sud;6|\n",
      "|           Albanie;1|\n",
      "|           Algérie;0|\n",
      "|        Allemagne;12|\n",
      "|            Angola;0|\n",
      "|   Arabie saoudite;2|\n",
      "|         Argentine;3|\n",
      "|       Arménie;;;;;5|\n",
      "|        Australie;10|\n",
      "+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.\\\n",
    "        builder.\\\n",
    "        appName(\"pyspark-notebook\").\\\n",
    "        master(\"spark://spark-master:7077\").\\\n",
    "        config(\"spark.executor.memory\", \"2g\").\\\n",
    "        getOrCreate()\n",
    "\n",
    "#df_load = sparkSession.read.csv('hdfs://Projet/data/Datasets_Emission_CO2.csv')\n",
    "#df_load.show()\n",
    "\n",
    "path  = \"hdfs://namenode:9000/Projet/data/Datasets_Emission_CO2.csv\"\n",
    "# lecture d'un fichier de manière la plus brute\n",
    "df_test  = spark.read.load(path, format=\"csv\")\n",
    "df_test.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+\n",
      "|             _c0| 1971| 1975| 1980| 1985| 1990| 1995| 2000| 2005| 2010| 2015| 2017|\n",
      "+----------------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+\n",
      "|  Afrique du Sud|  6,8|  7,9| 7,17| 6,76| 6,63| 6,27| 6,25| 7,82| 7,98| 7,46| 7,43|\n",
      "|         Albanie| 1,77|  1,8| 2,55| 2,34| 1,73| 0,58|    1| 1,27| 1,35| 1,33| 1,51|\n",
      "|         Algérie| 0,58| 0,81| 1,43| 1,86| 1,98| 1,92| 1,97| 2,33| 2,65| 3,27| 3,16|\n",
      "|       Allemagne|12,49|12,37|13,39|12,93|11,84|10,54| 9,97| 9,67| 9,45| 8,93|  8,7|\n",
      "|          Angola| 0,23| 0,26|  0,3| 0,27| 0,32| 0,27| 0,28| 0,31| 0,65| 0,71| 0,61|\n",
      "| Arabie saoudite| 2,08| 3,03|10,21| 8,93| 9,26|10,23| 11,3|12,47|15,28|16,84|16,16|\n",
      "|       Argentine| 3,39| 3,27| 3,39| 2,89| 3,04| 3,35| 3,76| 3,82| 4,22| 4,39| 4,14|\n",
      "|         Arménie| null| null| null| null| 5,61| 1,05| 1,12| 1,39| 1,41| 1,61| 1,76|\n",
      "|       Australie|10,86|12,85|13,96|13,84|15,03|15,66|17,36|18,18|17,42|15,72|15,63|\n",
      "|        Autriche| 6,48| 6,53|  7,2| 6,96| 7,33| 7,49| 7,72| 9,04| 8,17| 7,24| 7,38|\n",
      "+----------------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test = spark.read.options(header='True', delimiter=';') \\\n",
    "  .csv(\"hdfs://namenode:9000/Projet/data/Datasets_Emission_CO2.csv\")\n",
    "df_test.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3) lecture avec les types détectés automatiquement\n",
    "Recharger le fichier avec  l'option inferShema.\n",
    "\n",
    "L'option 'inferSchema' permet de transformer les colonnes en types plus précis : entier  / booléens / chaines de caractères... bien sûr spark trouve les types uniquement si le fichier d'origine permet de les trouver de manière simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('id', 'int'),\n",
       " ('vitesse_a_pied', 'double'),\n",
       " ('vitesse_a_velo', 'double'),\n",
       " ('home', 'string'),\n",
       " ('travail', 'string'),\n",
       " ('sportif', 'boolean'),\n",
       " ('casseur', 'boolean'),\n",
       " ('statut', 'string'),\n",
       " ('salaire', 'double'),\n",
       " ('sexe', 'string'),\n",
       " ('age', 'int'),\n",
       " ('sportivite', 'double'),\n",
       " ('velo_perf_minimale', 'double')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.format('csv').options(header=True, inferSchema=True).load(path)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4) lecture avec schéma\n",
    "Il vous permet d'afficher le schéma de votre df, avec pour chaque colonne son nom, son type, et si elle accepte les valeurs nulles ou non. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(id,IntegerType,true),StructField(vitesse_a_pied,DoubleType,true),StructField(vitesse_a_velo,DoubleType,true),StructField(home,StringType,true),StructField(travail,StringType,true),StructField(sportif,BooleanType,true),StructField(casseur,BooleanType,true),StructField(statut,StringType,true),StructField(salaire,DoubleType,true),StructField(sexe,StringType,true),StructField(age,IntegerType,true),StructField(sportivite,DoubleType,true),StructField(velo_perf_minimale,DoubleType,true)))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous avez aussi la méthode printSchema() qui permet d'afficher le shéma du df de manière plus lisible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- vitesse_a_pied: double (nullable = true)\n",
      " |-- vitesse_a_velo: double (nullable = true)\n",
      " |-- home: string (nullable = true)\n",
      " |-- travail: string (nullable = true)\n",
      " |-- sportif: boolean (nullable = true)\n",
      " |-- casseur: boolean (nullable = true)\n",
      " |-- statut: string (nullable = true)\n",
      " |-- salaire: double (nullable = true)\n",
      " |-- sexe: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- sportivite: double (nullable = true)\n",
      " |-- velo_perf_minimale: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) écriture de la dataframe sur le disque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1) choix du format : csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "path file:/opt/workspace/csv already exists.;",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/sql/readwriter.py:827\u001b[0m, in \u001b[0;36mDataFrameWriter.save\u001b[0;34m(self, path, format, mode, partitionBy, **options)\u001b[0m\n\u001b[1;32m    825\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jwrite\u001b[38;5;241m.\u001b[39msave()\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 827\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/py4j/java_gateway.py:1304\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1298\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1299\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1300\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1301\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1303\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1304\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1307\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1308\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/sql/utils.py:137\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    133\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconverted\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(e)\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: path file:/opt/workspace/csv already exists.;"
     ]
    }
   ],
   "source": [
    "df.write.format(\"csv\").save(\"./csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2) choix du format : parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "path file:/opt/workspace/parquet already exists.;",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparquet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./parquet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/sql/readwriter.py:827\u001b[0m, in \u001b[0;36mDataFrameWriter.save\u001b[0;34m(self, path, format, mode, partitionBy, **options)\u001b[0m\n\u001b[1;32m    825\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jwrite\u001b[38;5;241m.\u001b[39msave()\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 827\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/py4j/java_gateway.py:1304\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1298\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1299\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1300\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1301\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1303\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1304\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1307\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1308\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/sql/utils.py:137\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    133\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconverted\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(e)\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: path file:/opt/workspace/parquet already exists.;"
     ]
    }
   ],
   "source": [
    "\n",
    "df.write.format(\"parquet\").save(\"./parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3) choix du format : json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "path file:/opt/workspace/json_data already exists.;",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./json_data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjson\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/sql/readwriter.py:827\u001b[0m, in \u001b[0;36mDataFrameWriter.save\u001b[0;34m(self, path, format, mode, partitionBy, **options)\u001b[0m\n\u001b[1;32m    825\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jwrite\u001b[38;5;241m.\u001b[39msave()\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 827\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/py4j/java_gateway.py:1304\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1298\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1299\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1300\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1301\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1303\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1304\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1307\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1308\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/sql/utils.py:137\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    133\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconverted\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(e)\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: path file:/opt/workspace/json_data already exists.;"
     ]
    }
   ],
   "source": [
    "df.write.save(\"./json_data\", format=\"json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv  parquet  ville  ville_1.csv\n"
     ]
    }
   ],
   "source": [
    "!ls ./data_velo/Villes/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4) lecture de différents formats\n",
    "Vous pouvez choisir de lire le df sous un format ou un autre en utilisant l'argument format dans la fonction spark.read.load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[age: bigint, casseur: boolean, home: string, id: bigint, salaire: double, sexe: string, sportif: boolean, sportivite: double, statut: string, travail: string, velo_perf_minimale: double, vitesse_a_pied: double, vitesse_a_velo: double]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read.load(\"./json_data\", format=\"json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read.load(\"./data_velo/Villes/ville/\", format=\"csv\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Calculer des résultats : les actions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1) nombre de lignes : count\n",
    "Chargez les fichiers csv contenus dans le dossiers ./data_velo/Cyclistes/ dans un df nommé cyclistes, puis comptez les lignes du dataframe obtenu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cycliste_10.csv  cycliste_22.csv  cycliste_34.csv  cycliste_46.csv\n",
      "cycliste_11.csv  cycliste_23.csv  cycliste_35.csv  cycliste_47.csv\n",
      "cycliste_12.csv  cycliste_24.csv  cycliste_36.csv  cycliste_48.csv\n",
      "cycliste_13.csv  cycliste_25.csv  cycliste_37.csv  cycliste_49.csv\n",
      "cycliste_14.csv  cycliste_26.csv  cycliste_38.csv  cycliste_5.csv\n",
      "cycliste_15.csv  cycliste_27.csv  cycliste_39.csv  cycliste_50.csv\n",
      "cycliste_16.csv  cycliste_28.csv  cycliste_4.csv   cycliste_51.csv\n",
      "cycliste_17.csv  cycliste_29.csv  cycliste_40.csv  cycliste_6.csv\n",
      "cycliste_18.csv  cycliste_3.csv   cycliste_41.csv  cycliste_7.csv\n",
      "cycliste_19.csv  cycliste_30.csv  cycliste_42.csv  cycliste_8.csv\n",
      "cycliste_2.csv\t cycliste_31.csv  cycliste_43.csv  cycliste_9.csv\n",
      "cycliste_20.csv  cycliste_32.csv  cycliste_44.csv\n",
      "cycliste_21.csv  cycliste_33.csv  cycliste_45.csv\n"
     ]
    }
   ],
   "source": [
    "!ls ./data_velo/Cyclistes/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2232050"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read.load(\"./data_velo/Cyclistes/\", format=\"csv\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afficher le schéma de ce nouveau df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('id', 'int'),\n",
       " ('timestamp', 'string'),\n",
       " ('sur_velo', 'boolean'),\n",
       " ('velo', 'string'),\n",
       " ('vitesse', 'double'),\n",
       " ('position', 'string'),\n",
       " ('destination_finale', 'string')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"./data_velo/Cyclistes/\"\n",
    "#df   = spark.read.load(path, format=\"csv\")\n",
    "df = spark.read.format('csv').options(header=True, inferSchema=True).load(path)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichez 10 lignes du df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 17:=================================================>        (6 + 1) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- sur_velo: boolean (nullable = true)\n",
      " |-- velo: string (nullable = true)\n",
      " |-- vitesse: double (nullable = true)\n",
      " |-- position: string (nullable = true)\n",
      " |-- destination_finale: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(id=12, timestamp='2018-01-01 00:01:00', sur_velo=False, velo='False', vitesse=0.030000000000000006, position='(lon:2.07 lat:1.24)', destination_finale='False'),\n",
       " Row(id=12, timestamp='2018-01-01 00:02:00', sur_velo=False, velo='False', vitesse=0.030000000000000006, position='(lon:2.07 lat:1.24)', destination_finale='False'),\n",
       " Row(id=12, timestamp='2018-01-01 00:03:00', sur_velo=False, velo='False', vitesse=0.030000000000000006, position='(lon:2.07 lat:1.24)', destination_finale='False'),\n",
       " Row(id=12, timestamp='2018-01-01 00:04:00', sur_velo=False, velo='False', vitesse=0.030000000000000006, position='(lon:2.07 lat:1.24)', destination_finale='False'),\n",
       " Row(id=12, timestamp='2018-01-01 00:05:00', sur_velo=False, velo='False', vitesse=0.030000000000000006, position='(lon:2.07 lat:1.24)', destination_finale='False'),\n",
       " Row(id=12, timestamp='2018-01-01 00:06:00', sur_velo=False, velo='False', vitesse=0.030000000000000006, position='(lon:2.07 lat:1.24)', destination_finale='False'),\n",
       " Row(id=12, timestamp='2018-01-01 00:07:00', sur_velo=False, velo='False', vitesse=0.030000000000000006, position='(lon:2.07 lat:1.24)', destination_finale='False'),\n",
       " Row(id=12, timestamp='2018-01-01 00:08:00', sur_velo=False, velo='False', vitesse=0.030000000000000006, position='(lon:2.07 lat:1.24)', destination_finale='False'),\n",
       " Row(id=12, timestamp='2018-01-01 00:09:00', sur_velo=False, velo='False', vitesse=0.030000000000000006, position='(lon:2.07 lat:1.24)', destination_finale='False'),\n",
       " Row(id=12, timestamp='2018-01-01 00:10:00', sur_velo=False, velo='False', vitesse=0.030000000000000006, position='(lon:2.07 lat:1.24)', destination_finale='False')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"./data_velo/Cyclistes/\"\n",
    "#df   = spark.read.load(path, format=\"csv\")\n",
    "df = spark.read.format('csv').options(header=True, inferSchema=True).load(path)\n",
    "df.dtypes\n",
    "df.printSchema()\n",
    "df.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2) moyenne : agg + colonne + mean\n",
    "A l'aide de la méthode agg(), calculez la moyenne sur la colonne vitesse.\n",
    "\n",
    "Vous pouvez récuperer le résultat avec la méthode collect()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 19:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|      avg(vitesse)|\n",
      "+------------------+\n",
      "|0.4423137464018649|\n",
      "+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.agg({\"vitesse\":\"mean\"}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3) quantile approximatifs pour gagner du temps de calcul\n",
    "En statistiques et en théorie des probabilités, les quantiles sont les valeurs qui divisent un jeu de données en intervalles contenant le même nombre de données. Il y a donc un quantile de moins que le nombre de groupes créés. Ainsi les quartiles sont les trois quantiles qui divisent un ensemble de données en quatre groupes de taille égale.\n",
    "\n",
    "La méthode approxQuantile permet de laisser une tolérance a l'erreur ce qui réduit le temps de calul sur d'énormes jeux de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcul_quantile(df, erreur_acceptee):\n",
    "    debut            = time.time()\n",
    "    colonne          = \"vitesse\"\n",
    "    quantiles_voulus = [0.25, 0.50, 0.75]\n",
    "    resultat         =  df.approxQuantile(colonne, quantiles_voulus , erreur_acceptee )\n",
    "    fin              = time.time()\n",
    "    delais           = fin -debut\n",
    "    print (\"delais =%.2f sec, quantiles = %s\"%(delais, resultat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 21:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delais =3.85 sec, quantiles = [0.030000000000000006, 0.2944550644296354, 0.5931162118010243]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "calcul_quantile(df, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 22:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delais =4.14 sec, quantiles = [0.030000000000000006, 0.2944550644296354, 0.6295531740219638]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "calcul_quantile(df, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 23:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delais =7.28 sec, quantiles = [0.030000000000000006, 0.3283952876721612, 0.6295531740219638]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "calcul_quantile(df, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reload de la dataframe\n",
    "Chargez le fichier villes dans un df nommé villes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- vitesse_a_pied: double (nullable = true)\n",
      " |-- vitesse_a_velo: double (nullable = true)\n",
      " |-- home: string (nullable = true)\n",
      " |-- travail: string (nullable = true)\n",
      " |-- sportif: boolean (nullable = true)\n",
      " |-- casseur: boolean (nullable = true)\n",
      " |-- statut: string (nullable = true)\n",
      " |-- salaire: double (nullable = true)\n",
      " |-- sexe: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- sportivite: double (nullable = true)\n",
      " |-- velo_perf_minimale: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "villes =spark.read.load(\"./data_velo/villes/\", format=\"csv\", header=True, inferSchema=\"True\")\n",
    "villes.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4) corrélation\n",
    "En probabilités et en statistique, la corrélation entre plusieurs variables aléatoires ou statistiques est une notion de liaison qui contredit leur indépendance.\n",
    "\n",
    "Calculez la corrélation entre les colonnes age et vitesse_a_velo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.06411845578664936"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "villes.corr(col1= 'age', col2= 'vitesse_a_velo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5) covariance\n",
    "Calculez la covariance entre les colonnes age et vitesse_a_velo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.5721945755314064"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "villes.cov(col1= 'age', col2='vitesse_a_velo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6) sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "villes_1_pct = villes.sample(False, 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "villes_1_pct.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "villes.exceptAll(villes_1_pct).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7) filter \n",
    "La méthode filter() permet le df selon certaines valeurs dans les colonnes.\n",
    "\n",
    "Utilisez cette méthode pour récuperer seulement les lignes avec le sexe féminin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+-------------------+-------------------+-------------------+-------+-------+--------------------+------------------+----+---+-------------------+------------------+\n",
      "| id|     vitesse_a_pied|     vitesse_a_velo|               home|            travail|sportif|casseur|              statut|           salaire|sexe|age|         sportivite|velo_perf_minimale|\n",
      "+---+-------------------+-------------------+-------------------+-------------------+-------+-------+--------------------+------------------+----+---+-------------------+------------------+\n",
      "|  3|               0.02|               0.05|(lon:3.79 lat:3.81)|(lon:0.20 lat:0.21)|  false|  false|technicien_de_sur...| 20026.72646423192|   F| 20|                0.1|               0.4|\n",
      "|  4|               0.02|               0.05|(lon:3.39 lat:0.93)|(lon:0.58 lat:0.20)|  false|  false|technicien_de_sur...|15214.584161640825|   F| 35|                0.1|               0.4|\n",
      "|  6|               0.02|               0.05|(lon:0.44 lat:1.45)|(lon:1.85 lat:0.04)|  false|  false|          professeur|30852.120709809133|   F| 79|                0.1|               0.4|\n",
      "|  7| 0.9726853575358816|  2.431713393839704|(lon:0.18 lat:2.60)|(lon:2.16 lat:2.28)|  false|  false|             employe| 54494.87538632937|   F| 46|  4.863426787679408|               0.4|\n",
      "|  9| 0.6295531740219638| 1.5738829350549093|(lon:2.16 lat:2.32)|(lon:3.44 lat:3.54)|  false|  false|technicien_de_sur...|11799.927798039249|   F| 65| 3.1477658701098186|               0.4|\n",
      "| 11|0.25214291732243804|  0.630357293306095|(lon:0.28 lat:2.44)|(lon:1.28 lat:1.40)|  false|  false|             employe|  53716.3729157698|   F| 21|   1.26071458661219|               0.4|\n",
      "| 14| 0.3733552690301726| 0.9333881725754316|(lon:3.87 lat:3.74)|(lon:0.41 lat:0.36)|  false|  false|               cadre|  74308.6319691613|   F| 34|  1.866776345150863|               0.4|\n",
      "| 16|               0.02|               0.05|(lon:1.37 lat:1.09)|(lon:0.45 lat:1.77)|  false|  false|             éboueur|21040.289070523115|   F| 32|                0.1|               0.4|\n",
      "| 17| 1.0608622097751907| 2.6521555244379766|(lon:3.68 lat:0.79)|(lon:2.67 lat:3.66)|  false|  false|technicien_de_sur...|16946.365288912493|   F| 16|  5.304311048875953|               0.4|\n",
      "| 18|               0.02|               0.05|(lon:0.51 lat:2.32)|(lon:1.01 lat:0.40)|  false|  false|technicien_de_sur...|22099.145463261266|   F| 24|                0.1|               0.4|\n",
      "| 22| 0.5931162118010243| 1.4827905295025607|(lon:1.41 lat:2.43)|(lon:1.49 lat:1.44)|  false|  false|             employe|38906.393030229774|   F| 36|  2.965581059005121|               0.4|\n",
      "| 23| 0.1431743884246346| 0.3579359710615865|(lon:0.80 lat:2.82)|(lon:0.34 lat:3.77)|  false|  false|             employe|29085.686473822872|   F| 78| 0.7158719421231731|               0.4|\n",
      "| 27| 0.4804764997211946| 1.2011912493029866|(lon:0.78 lat:2.62)|(lon:2.30 lat:0.01)|  false|  false|technicien_de_sur...|18234.071705216207|   F| 59|  2.402382498605973|               0.4|\n",
      "| 29|0.07468040314496042|0.18670100786240107|(lon:3.75 lat:3.12)|(lon:2.30 lat:3.92)|  false|  false|          reserviste|29515.863019061188|   F| 67| 0.3734020157248021|               0.4|\n",
      "| 30| 0.5525664880322532| 1.3814162200806333|(lon:1.08 lat:3.77)|(lon:0.72 lat:3.32)|  false|  false|             employe|27046.171282769843|   F| 81| 2.7628324401612665|               0.4|\n",
      "| 34|0.03887047976999849|0.09717619942499622|(lon:2.83 lat:0.56)|(lon:3.25 lat:1.60)|  false|  false|technicien_de_sur...|17175.758356245642|   F| 21|0.19435239884999245|               0.4|\n",
      "| 42| 0.6992238313299156| 1.7480595783247892|(lon:3.80 lat:3.99)|(lon:2.13 lat:1.65)|  false|  false|             employe| 19383.17526928032|   F| 21| 3.4961191566495784|               0.4|\n",
      "| 47|0.18444538804220728| 0.4611134701055182|(lon:1.74 lat:3.62)|(lon:2.96 lat:2.23)|  false|  false|          reserviste| 30798.10624851897|   F| 58| 0.9222269402110364|               0.4|\n",
      "| 48| 0.5652688776055729|  1.413172194013932|(lon:3.51 lat:2.24)|(lon:0.27 lat:1.34)|  false|  false|             éboueur|12133.681930505132|   F| 56| 2.8263443880278643|               0.4|\n",
      "| 49| 0.9920385410084079|   2.48009635252102|(lon:0.13 lat:2.04)|(lon:1.35 lat:0.63)|  false|  false|technicien_de_sur...| 9511.945356442959|   F| 58|   4.96019270504204|               0.4|\n",
      "+---+-------------------+-------------------+-------------------+-------------------+-------+-------+--------------------+------------------+----+---+-------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "villes.filter(\"sexe = 'F'\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Transformer la données : les transformations!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformations : demandent à être suivi par un collect ou une action (count par exemple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1) obtenir des statistiques sur les colonnes numériques\n",
    "La méthode describe() permet de calculer les statistiques récapitulatives d'une ou plusieurs colonnes numériques dans un df. Si le nom des colonnes n'est pas spécifié, la méthode calculera des statistiques récapitulatives pour toutes les colonnes numériques présentes dans le df.\n",
    "\n",
    "Afficher les statistiques de la colonne age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(summary='count', summary='5', sexe='3', age='5'),\n",
       " Row(summary='mean', summary=None, sexe='50.0', age='43.43979797464467'),\n",
       " Row(summary='stddev', summary=None, sexe='NaN', age='27.13153036418277'),\n",
       " Row(summary='min', summary='count', sexe='50', age='16'),\n",
       " Row(summary='max', summary='stddev', sexe='H', age='83')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "villes.describe([\"sexe\", \"age\"]).describe().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2) groupby\n",
    "La méthode groupBy() suivie de la methode agg() permet de grouper le df selon les catgories d'une ou plusieurs colonnes pour faire des calculs sur ces catégories.\n",
    "\n",
    "Calculez la moyenne de la colonnes sportivité selon le sexe des personnes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+\n",
      "|sexe|   avg(sportivite)|\n",
      "+----+------------------+\n",
      "|   F|1.8410619134680517|\n",
      "|   H|1.6356186755623958|\n",
      "+----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "villes.groupBy(\"sexe\").agg({\"sportivite\":'mean'}).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculez la moyenne de la colonne age et la valeur max de la colonne sportivité par sexe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------------+------------------+\n",
      "|sexe|  max(sportivite)|          avg(age)|\n",
      "+----+-----------------+------------------+\n",
      "|   F|5.304311048875953|46.095238095238095|\n",
      "|   H|7.814024407120282| 50.06896551724138|\n",
      "+----+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "villes.groupBy(\"sexe\").agg({\"age\":'mean' ,\"sportivite\":'max'}).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculez la moyenne des colonnes vitesse_a_pied et vitesse_a_velo par sexe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------------+-------------------+\n",
      "|sexe|avg(vitesse_a_velo)|avg(vitesse_a_pied)|\n",
      "+----+-------------------+-------------------+\n",
      "|   F| 0.9205309567340259|0.36821238269361034|\n",
      "|   H| 1.3084949404499162| 0.4906856026687184|\n",
      "+----+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "villes.groupBy(\"sexe\").agg({\"vitesse_a_pied\":'mean',\"vitesse_a_velo\":'mean'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3) summary \n",
    "La méthode summary() permet des faire des calculs statistiques de base sur toutes les colonnes du df.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(summary='count', id='50', vitesse_a_pied='50', vitesse_a_velo='50', home='50', travail='50', statut='50', salaire='50', sexe='50', age='50', sportivite='50', velo_perf_minimale='50'),\n",
       " Row(summary='max', id='51', vitesse_a_pied='2.344207322136085', vitesse_a_velo='6.251219525696226', home='(lon:3.90 lat:0.62)', travail='(lon:3.91 lat:3.22)', statut='éboueur', salaire='148702.7189509448', sexe='H', age='83', sportivite='7.814024407120282', velo_perf_minimale='0.4')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "villes.summary(\"count\", \"max\").collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4) union de dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ajouter les colonnes les unes à côté des autres : join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- vitesse_a_pied: double (nullable = true)\n",
      " |-- vitesse_a_velo: double (nullable = true)\n",
      " |-- home: string (nullable = true)\n",
      " |-- travail: string (nullable = true)\n",
      " |-- sportif: boolean (nullable = true)\n",
      " |-- casseur: boolean (nullable = true)\n",
      " |-- statut: string (nullable = true)\n",
      " |-- salaire: double (nullable = true)\n",
      " |-- sexe: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- sportivite: double (nullable = true)\n",
      " |-- velo_perf_minimale: double (nullable = true)\n",
      " |-- vitesse_a_pied: double (nullable = true)\n",
      " |-- vitesse_a_velo: double (nullable = true)\n",
      " |-- home: string (nullable = true)\n",
      " |-- travail: string (nullable = true)\n",
      " |-- sportif: boolean (nullable = true)\n",
      " |-- casseur: boolean (nullable = true)\n",
      " |-- statut: string (nullable = true)\n",
      " |-- salaire: double (nullable = true)\n",
      " |-- sexe: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- sportivite: double (nullable = true)\n",
      " |-- velo_perf_minimale: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "villes.join(villes, on=\"id\").printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ajouter les lignes les unes sous les autres : union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "villes.unionByName(villes).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5) filtre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "villes.where(villes.sexe==\"F\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6) concaténation de colonne : F.concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql       import functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons ici reprendre le df cyclistes.\n",
    "\n",
    "Utiliser les méthodes withColumn() et F.concat() pour ajouter une colonne au df qui contiendra la concatenation des valeurs des colonnes id et sur_velo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Row(id=12, timestamp='2018-01-01 00:01:00', sur_velo=False, velo='False', vitesse=0.030000000000000006, position='(lon:2.07 lat:1.24)', destination_finale='False', id_sur_velo='12false')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"./data_velo/Cyclistes/*.csv\" \n",
    "tous_les_cyclistes = spark.read.format(\"csv\").option(\"header\", \"true\").load(path, inferSchema=True)\n",
    "tous_les_cyclistes.count()\n",
    "tous_les_cyclistes.withColumn(\"id_sur_velo\", F.concat(tous_les_cyclistes.id,  tous_les_cyclistes.sur_velo)).first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) udf \n",
    "Il est possible d'enregistrer des fonctions python que l'on écrit nous même pour les appliquer sur une colonne d'une dataframe, c'est ce qu'on appelle les udf, pour User Defined Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types     import *\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "@udf(returnType = FloatType())\n",
    "def cube(colonne):\n",
    "    return colonne*colonne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|cube(salaire)|\n",
      "+-------------+\n",
      "|1.82702162E10|\n",
      "|  4.0106976E8|\n",
      "| 2.31483568E8|\n",
      "| 3.32549088E8|\n",
      "|  9.5185338E8|\n",
      "| 2.96969139E9|\n",
      "| 1.12880461E9|\n",
      "| 1.39238304E8|\n",
      "|  1.0977216E9|\n",
      "|  2.8854487E9|\n",
      "|  6.4748621E8|\n",
      "| 1.22958438E9|\n",
      "|  5.5217725E9|\n",
      "| 2.57463706E9|\n",
      "|  4.4269376E8|\n",
      "| 2.87179296E8|\n",
      "| 4.88372224E8|\n",
      "|  6.9554765E9|\n",
      "|  6.1511916E9|\n",
      "|   5.757398E9|\n",
      "+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "villes.select(cube(\"salaire\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|cube(salaire)|\n",
      "+-------------+\n",
      "|1.82702162E10|\n",
      "|  4.0106976E8|\n",
      "| 2.31483568E8|\n",
      "| 3.32549088E8|\n",
      "|  9.5185338E8|\n",
      "| 2.96969139E9|\n",
      "| 1.12880461E9|\n",
      "| 1.39238304E8|\n",
      "|  1.0977216E9|\n",
      "|  2.8854487E9|\n",
      "|  6.4748621E8|\n",
      "| 1.22958438E9|\n",
      "|  5.5217725E9|\n",
      "| 2.57463706E9|\n",
      "|  4.4269376E8|\n",
      "| 2.87179296E8|\n",
      "| 4.88372224E8|\n",
      "|  6.9554765E9|\n",
      "|  6.1511916E9|\n",
      "|   5.757398E9|\n",
      "+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "villes.select(cube(villes.salaire)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(cube(salaire)=18270216192.0),\n",
       " Row(cube(salaire)=401069760.0),\n",
       " Row(cube(salaire)=231483568.0),\n",
       " Row(cube(salaire)=332549088.0),\n",
       " Row(cube(salaire)=951853376.0),\n",
       " Row(cube(salaire)=2969691392.0),\n",
       " Row(cube(salaire)=1128804608.0),\n",
       " Row(cube(salaire)=139238304.0),\n",
       " Row(cube(salaire)=1097721600.0),\n",
       " Row(cube(salaire)=2885448704.0),\n",
       " Row(cube(salaire)=647486208.0),\n",
       " Row(cube(salaire)=1229584384.0),\n",
       " Row(cube(salaire)=5521772544.0),\n",
       " Row(cube(salaire)=2574637056.0),\n",
       " Row(cube(salaire)=442693760.0),\n",
       " Row(cube(salaire)=287179296.0),\n",
       " Row(cube(salaire)=488372224.0),\n",
       " Row(cube(salaire)=6955476480.0),\n",
       " Row(cube(salaire)=6151191552.0),\n",
       " Row(cube(salaire)=5757398016.0),\n",
       " Row(cube(salaire)=1513707392.0),\n",
       " Row(cube(salaire)=845977152.0),\n",
       " Row(cube(salaire)=15607006208.0),\n",
       " Row(cube(salaire)=279298720.0),\n",
       " Row(cube(salaire)=658956352.0),\n",
       " Row(cube(salaire)=332481376.0),\n",
       " Row(cube(salaire)=11568824320.0),\n",
       " Row(cube(salaire)=871186176.0),\n",
       " Row(cube(salaire)=731495360.0),\n",
       " Row(cube(salaire)=22112497664.0),\n",
       " Row(cube(salaire)=1202230528.0),\n",
       " Row(cube(salaire)=423060096.0),\n",
       " Row(cube(salaire)=295006688.0),\n",
       " Row(cube(salaire)=1184019968.0),\n",
       " Row(cube(salaire)=229316384.0),\n",
       " Row(cube(salaire)=4948908544.0),\n",
       " Row(cube(salaire)=880376512.0),\n",
       " Row(cube(salaire)=993021504.0),\n",
       " Row(cube(salaire)=332946784.0),\n",
       " Row(cube(salaire)=155353856.0),\n",
       " Row(cube(salaire)=375707488.0),\n",
       " Row(cube(salaire)=421229280.0),\n",
       " Row(cube(salaire)=454536128.0),\n",
       " Row(cube(salaire)=5381703680.0),\n",
       " Row(cube(salaire)=596220544.0),\n",
       " Row(cube(salaire)=948523328.0),\n",
       " Row(cube(salaire)=147226240.0),\n",
       " Row(cube(salaire)=90477104.0),\n",
       " Row(cube(salaire)=988872128.0),\n",
       " Row(cube(salaire)=580938816.0)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "villes.select(cube(\"salaire\")).collect()\n",
    "#villes.withColumn(\"salaire\",cube(\"salaire\")).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6)\tEtude de cas : analyse des fichiers de logs des cyclistes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql       import functions as F\n",
    "from pyspark.sql.types     import *\n",
    "from pyspark.sql.functions import udf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1)  Charger la donnée dans un df nommé cycliste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "path = \"./data_velo/Cyclistes/*.csv\" \n",
    "cyclistes = spark.read.format('csv').options(header=True, inferSchema=True).load(path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2) vérifier le nombre de cycles\n",
    "\n",
    "Comptez le nombre d'id uniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cyclistes.select(\"id\").distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3) transformer les timestamp en date\n",
    "\n",
    "Voici une fonction qui permert de récuperer la date sous forme de chaîne de caractère dans la colonne timestamps pour la transformer en date exploitable en tant que telle.\n",
    "\n",
    "Créez une nouvelle colonne dans votre df cycliste stockant le résultat de cette fonction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import TimestampType\n",
    "\n",
    "@udf(returnType = TimestampType())\n",
    "def transform_timestamp_in_date(timestamp):\n",
    "    from datetime import datetime\n",
    "    return datetime.strptime(str(timestamp), \"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+--------+-----+--------------------+-------------------+------------------+-------------------+\n",
      "| id|          timestamp|sur_velo| velo|             vitesse|           position|destination_finale|       result_final|\n",
      "+---+-------------------+--------+-----+--------------------+-------------------+------------------+-------------------+\n",
      "| 12|2018-01-01 00:01:00|   false|False|0.030000000000000006|(lon:2.07 lat:1.24)|             False|2018-01-01 00:01:00|\n",
      "| 12|2018-01-01 00:02:00|   false|False|0.030000000000000006|(lon:2.07 lat:1.24)|             False|2018-01-01 00:02:00|\n",
      "| 12|2018-01-01 00:03:00|   false|False|0.030000000000000006|(lon:2.07 lat:1.24)|             False|2018-01-01 00:03:00|\n",
      "| 12|2018-01-01 00:04:00|   false|False|0.030000000000000006|(lon:2.07 lat:1.24)|             False|2018-01-01 00:04:00|\n",
      "| 12|2018-01-01 00:05:00|   false|False|0.030000000000000006|(lon:2.07 lat:1.24)|             False|2018-01-01 00:05:00|\n",
      "| 12|2018-01-01 00:06:00|   false|False|0.030000000000000006|(lon:2.07 lat:1.24)|             False|2018-01-01 00:06:00|\n",
      "| 12|2018-01-01 00:07:00|   false|False|0.030000000000000006|(lon:2.07 lat:1.24)|             False|2018-01-01 00:07:00|\n",
      "| 12|2018-01-01 00:08:00|   false|False|0.030000000000000006|(lon:2.07 lat:1.24)|             False|2018-01-01 00:08:00|\n",
      "| 12|2018-01-01 00:09:00|   false|False|0.030000000000000006|(lon:2.07 lat:1.24)|             False|2018-01-01 00:09:00|\n",
      "| 12|2018-01-01 00:10:00|   false|False|0.030000000000000006|(lon:2.07 lat:1.24)|             False|2018-01-01 00:10:00|\n",
      "| 12|2018-01-01 00:11:00|   false|False|0.030000000000000006|(lon:2.07 lat:1.24)|             False|2018-01-01 00:11:00|\n",
      "| 12|2018-01-01 00:12:00|   false|False|0.030000000000000006|(lon:2.07 lat:1.24)|             False|2018-01-01 00:12:00|\n",
      "| 12|2018-01-01 00:13:00|   false|False|0.030000000000000006|(lon:2.07 lat:1.24)|             False|2018-01-01 00:13:00|\n",
      "| 12|2018-01-01 00:14:00|   false|False|0.030000000000000006|(lon:2.07 lat:1.24)|             False|2018-01-01 00:14:00|\n",
      "| 12|2018-01-01 00:15:00|   false|False|0.030000000000000006|(lon:2.07 lat:1.24)|             False|2018-01-01 00:15:00|\n",
      "| 12|2018-01-01 00:16:00|   false|False|0.030000000000000006|(lon:2.07 lat:1.24)|             False|2018-01-01 00:16:00|\n",
      "| 12|2018-01-01 00:17:00|   false|False|0.030000000000000006|(lon:2.07 lat:1.24)|             False|2018-01-01 00:17:00|\n",
      "| 12|2018-01-01 00:18:00|   false|False|0.030000000000000006|(lon:2.07 lat:1.24)|             False|2018-01-01 00:18:00|\n",
      "| 12|2018-01-01 00:19:00|   false|False|0.030000000000000006|(lon:2.07 lat:1.24)|             False|2018-01-01 00:19:00|\n",
      "| 12|2018-01-01 00:20:00|   false|False|0.030000000000000006|(lon:2.07 lat:1.24)|             False|2018-01-01 00:20:00|\n",
      "+---+-------------------+--------+-----+--------------------+-------------------+------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cyclistes.withColumn('result_final', transform_timestamp_in_date(cyclistes.timestamp)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4) Durée des trajets par id.\n",
    "\n",
    "A partir d'ici, il s'agit de traiter votre donnée pour récupérer la durée de chaque trajet effectué par chaque id.\n",
    "\n",
    "1) trouvez les dates min/max par état de sur_velo, puis par id ET par état de sur_velo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cyclistes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcyclistes\u001b[49m\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msur_velo\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39magg(F\u001b[38;5;241m.\u001b[39mmin(cyclistes[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m\"\u001b[39m]), F\u001b[38;5;241m.\u001b[39mmax(cyclistes[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\u001b[38;5;241m.\u001b[39msort(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mshoow()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cyclistes' is not defined"
     ]
    }
   ],
   "source": [
    "cyclistes.groupby([\"id\", \"sur_velo\"]).agg(F.min(cyclistes[\"timestamp\"]), F.max(cyclistes[\"timestamp\"])).sort(\"id\").shoow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5) détecter les changements d'états \"sur un vélo\" ou pas : window et lag\n",
    "2) Le résultat n'est pas trés pertinent, il faudrait plutôt le début et la fin de chaque trajet par id. Pour cela, il faudrait détecter les changements d'états \"sur_vélo\".\n",
    "Utilisez la classe Window() et la fonction F.lag() pour créer une nouvelle colonne que vous appellerez changement, contenant un 0 si l'état précedent de sur_velo est le même et un 1 si l'état vient de changer (fonction changement() ci-dessous) pour chaque id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf(returnType = IntegerType())\n",
    "def changement(etat_actuel, etat_precedent):\n",
    "    \"\"\"\n",
    "    Détecte si les deux états sont différent.\n",
    "    \n",
    "    Parametres :\n",
    "        etat_actuel : valeur sur la ligne courante\n",
    "                      renvoyée par F.lag (0)\n",
    "        etat_precedent : valeur sur la ligne précédente\n",
    "                      renvoyée par F.lag(1)\n",
    "    Return: 0 s'ils sont égaux, 1 s'il y a une différence\n",
    "    \"\"\"\n",
    "    if etat_precedent == None:\n",
    "        return 0\n",
    "    if etat_precedent == etat_actuel:\n",
    "        return 0\n",
    "    if etat_actuel != etat_precedent:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "w = Window.orderBy([\"id\", \"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "collecter les données d'un id et verifier sa position lors des changements d'etats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.6) somme partielle par sous groupe : windows\n",
    "Grâce à la fonction window appliquez la fonction somme() sur la colonne changement pour numeroter les trajets pour chaque id et stocker les résulats dans une nouvelle colonne appelée numero_de_trajet.\n",
    "\n",
    "\n",
    "[windows fonctions](https://www.quantmetry.com/blog/window-functions-spark/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf(returnType = IntegerType())\n",
    "def somme(indice_actuel, indice_precedent):\n",
    "    if indice_precedent == None:\n",
    "        return 0\n",
    "    return indice_actuel + indice_precedent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.7) Calculer la durée du trajet\n",
    "\n",
    "Il suffit maintenant de repêter la première étape, c'est a dire récupérer la début et la fin de chaque trajet pour chaque id. Puis calculer la durée des trajets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7) datavisualisation\n",
    "Convertissez votre dataframe pyspark en dataframe pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A l'aide de la librairie seaborn, réalisez un graphique en barre montrant la durée de tout les trajets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faire le même graphique mais cette fois-ci, faire en sorte qu'on puisse choisir un id et afficher seulement les trajets de cet id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sauvegardez votre dataset trajets au format csv dans le dossier data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
